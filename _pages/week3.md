---
layout: "single"
title: "Genome-wide association testing"
toc: true
toc_label: "Contents"
permalink: /assignments/week3/
---

In this assignemnt we will combine the data-cleaning steps we learned in [Week 1](https://wletsou.github.io/assignments/week1) and [Week 2](https://wletsou.github.io/assignments/week2) to a simulated case-control study of disease.  We will create a simulated dataset from one of the 1KG populations, declare some alleles to be risk alleles, and find the association of each SNP with the simulated phenotype.  First we will give an overview of logistic regression and linear mixed models.

### Statistics ###

#### The odds ratio ####

The logic of any genetic association study is to see if an allele is enriched in subjects affected with disease.  In other words, we want to see if the allele is *associated* with disease.  We do this by collecting may individuals with disease and a similar number of healthy controls from the general popuation.  An individual's risk is the probability \\(p=P\left(\text{Disease}\mid\text{Allele}\right)\\) of developing disease over a lifetime, and the *relative risk* or RR is the ratio of the risk to carriers to the risk to non-carriers of the allele.  However, the RR is difficult to measure because it involves waiting a long time for a potentially smaller number of cases to develop.  If we pre-select cases and controls, we can instead calculate the probability \\(P\left(\text{Allele}\mid\text{Disease}\right)\\) of carrying the allele conditioned on an individual's disease status.  Related to probability is the *odds* \\(\frac{p}{1-p}\\) of the the event, and it turns out that the *odds ratio*\\[\text{OR}=\frac{\frac{P\left(\text{Allele}\mid\text{Cases}\right)}{1-P\left(\text{Allele}\mid\text{Cases}\right)}}{\frac{P\left(\text{Allele}\mid\text{Controls}\right)}{1-P\left(\text{Allele}\mid\text{Controls}\right)}}\tag{1}\\]is invariant to whether we collect subjects prospectively or retrospectively.  Hence we use the OR as a convenient measure the effect of an allele on disease risk in case-control studies. However, the crude measure (1) cannot be adjusted for other factors like sex, age, and race which may also have an effect on disease risk.  For this type of analysis, we need logistic regression.

#### The logistic model of disease risk ####

Normally we test the association between two variables using regression analysis, but doing so requires that both the dependent and independent variables be continuous.  In genetic association studies, neither the outcome (disease) nor the predictor (number of risk alleles) is continuous.  However, an individual's unobserved probability \\(p\\) is a continuous variable that ranges between 0 and 1; furthermore, the individual's *log-odds* \\(\log{\frac{p}{1-p}}\\) of disease is a continuous value that ranges between \\(-\infty\\) and \\(+\infty\\).  Thus if we assume that the log-odds of disease can be represented by the equation \\[\log{\frac{p}{1-p}}=\beta_0+\beta_1X_1,\tag{2}\\] where \\(X_1\\) is number of risk alleles and \\(\beta_1\\) is the *log-odds-ratio*, then we can in principle fit a line and estimate its slope.  This slope \\(\beta_1\\) would then be interpretted as the multiplicative increase in the log-odds of disease.

Now, since we cannot observe \\(p_i\\) for each subject \\(i\\), we cannot actually fit (2) using linear regression.  We can, however, use the concept of *maximum likelihood*.  In statistics, the likelihood of a disease model like (2) is the probability of the data being generated the model, or\\[\mathcal{L}\left(\text{Model}\mid\text{Data}\right)=P\left(\text{Data}\mid\text{Model}\right).\tag{3}\\]Here the model is the set of parameters \\(\beta_0,\beta_1\\) required to predict disease risk, and we can find estimates for the parameters by maximizing (3), i.e., by finding the model most consistent with the data.  Furthermore, if the likelihood function has approximately the shape of a normal distribution, then we can estimate the statistical significance of our estimates by computing their standard error, got from the *curvature* or second derivative of \\(\mathcal{L}\\) near the \\(\beta\\) which maximize it.

The binomial distribution is a good approximation to the normal distribution, so if we model the likelihood of the observed data as\\[\mathcal{L}=\prod_ip_i^{y_i}\left(1-p_i\right)^{1-y_i},\\] where \\(y_i=0,1\\) is an indicator of disease status, then the *log-likelihood* is\\[\begin{align}\ell&=\sum_iy_i\log{p_i}+\left(1-y_i\right)\log{\left(1-p_i\right)}\\\\\\ &=\sum_iy_i\log{\frac{p_i}{1-p_i}}+\log{\left(1-p_i\right)}\end{align}\\]or using (2)\\[\ell=\sum_iy_i\left(\beta_0+\beta_1X_{i1}\right)-\log{\left(1+e^{\beta_0+\beta_1X_{i1}}\right)}.\tag{4}\\]Eq. (4) is a function of the parameter \\(\beta_1\\).  Thus we can find the *maximum-likelihood estimate* \\(\hat{\beta_1}\\) of \\(\beta_1\\) by solving \\(\frac{\partial \ell}{\partial \beta_1}=0\\) and get its standard error \\(\frac{-1}{\frac{\partial^2\ell}{\partial \beta_1^2}\bigr\rvert_{\beta_1=\hat{\beta_1}}}\\)by evaluating the curvature of the log-likelihood at the best estimate of \\(\beta_1\\).  From these we can also get an estimate of the statistical significance.

#### Linear mixed models ####

In genome-wide association studies (GWAS) we'd like to estimate the odds ratio \\(e^\beta_1}\\) for each SNP to see if any SNPs are associated with disease.  However, there are millions of SNPs and only thousands of subjects, so we cannot fit all the parameters simultaneously.  Instead, one SNP effect \\(\beta_1\\) is fit at a time together with other the covariate effects \\(\beta_j\\) against a background of the composite effect of all the remaining SNPs together, so that our model has two components:\\[Y_i=\log{\frac{p_i}{1-p_i}}=\sum_jX_{ij}\beta_j+\sum_jZ_{ij}u_j+\varepsilon_i.\tag{5}\\]Here, \\(\mathbf{Z}\\) is an \\(n\times m\\) matrix of the (standardized) genotypes of \\(n\\) individuals at \\(m\\) SNPs and \\(u_j\\) is the effect of SNP \\(j\\) on the log-odds for individual \\(i\\).  The mixed-model framework assumes the \\(u\\) come from a normal distribution with mean 0 and standard deviation \\(\sigma\\), so that each variant has but a small effect on disease risk.  

Now, the variance of the log-odds \\(Y\\) about its mean \\(\mathbf{X}\beta\\) becomes\\[\begin{align}\left(Y-\mathbf{X}\beta\right)\left(Y-\mathbf{X}\beta\right)^T&=\mathbf{Z}uu^T\mathbf{Z}^T+\varepsilon\varepsilon^T\\\\\\ &=\left(\mathbf{Z}\mathbf{Z}^T+\mathbf{I}\right)\sigma^2=\mathbf{V}.\end{align}\\]Rearranging and differntiating with respect to \\\(\beta_k\\) obtains (with summation over \\(i\\), \\(j\\), and \\(l\\))\\[\begin{align}V_{li}^{-1}X_{ik}\left(Y_l-X_{lj}\beta_j\right)^T+V_{il}^{-1}\left(Y_l-X_{lj}\beta_j\right)X^T_{ki}&=0\\\\\\ \left(X^T_{ki}V_{il}^{-1}Y_l-X^T_{ki}V_{il}^{-1}X_{lj}\beta_j\right)^T+\left(X^T_{ki}V_{il}^{-1}Y_l-X^T_{ki}V_{il}^{-1}X_{lj}\beta_j\right)&=0,\end{align}\\]since \\(\mathbf{V}\\) and hence \\(\mathbf{V}^{-1}\\) is a symmetric matrix.  Hence we get the maximum-likelihood solution\\[\mathbf{X}^T\left(\mathbf{I}+\mathbf{Z}\mathbf{Z}^T\right)^{-1}\mathbf{X}\hat{\beta}=\mathbf{X}^T\left(\mathbf{I}+\mathbf{Z}\mathbf{Z}^T\right)^{-1}Y,\tag{6}\\]where \\(\frac{1}{m}\mathbf{Z}\mathbf{Z}^T\\) is the genomic relationship matrix (GRM) we used to compute principle components in [Week 1](https://wletsou.github.io/assignments/week1).  Thus we can estimatimate the *fixed effects* \\(\beta\\)&mdash;including the SNP effect \\(\beta_1\\)&mdash;and their standard errors without fitting the *random effects* of every other SNP simultaneously.

### Simulating genotypes and phenotypes ###
